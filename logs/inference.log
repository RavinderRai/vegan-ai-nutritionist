2024-11-02 11:20:11,015 - inference - INFO - Loading AWS connections...
2024-11-02 11:20:14,611 - inference - INFO - Loading model uri for sagemaker deployment...
2024-11-02 11:20:16,017 - inference - INFO - Retrieving LLM image URI and deployment configuration...
2024-11-02 11:20:16,528 - inference - INFO - Deploying the model as a SageMaker endpoint...
2024-11-02 11:20:17,135 - inference - ERROR - Failed to deploy the model: Parameter validation failed:
Invalid type for parameter PrimaryContainer.Environment.initial_instance_count, value: 1, type: <class 'int'>, valid types: <class 'str'>
Invalid type for parameter PrimaryContainer.Environment.container_startup_health_check_timeout, value: 300, type: <class 'int'>, valid types: <class 'str'>
2024-11-02 11:20:17,137 - inference - INFO - Attempting to deploy the base model instead...
2024-11-02 11:26:21,228 - inference - INFO - Base model deployed successfully: HuggingFacePredictor: {'endpoint_name': 'huggingface-pytorch-tgi-inference-2024-11-02-14-20-18-389', 'sagemaker_session': <sagemaker.session.Session object at 0x000002D3E0F22E60>, 'serializer': <sagemaker.base_serializers.JSONSerializer object at 0x000002D3E04346A0>, 'deserializer': <sagemaker.base_deserializers.JSONDeserializer object at 0x000002D3E0436470>}
2024-11-02 11:26:21,234 - inference - ERROR - Failed to deploy the base model: type object 'datetime.datetime' has no attribute 'datetime'
2024-11-02 11:47:02,624 - inference - INFO - Loading AWS connections...
2024-11-02 11:47:06,135 - inference - INFO - Loading model uri for sagemaker deployment...
2024-11-02 11:47:07,309 - inference - INFO - Retrieving LLM image URI and deployment configuration...
2024-11-02 11:47:07,835 - inference - INFO - Deploying the model as a SageMaker endpoint...
2024-11-02 11:47:08,444 - inference - ERROR - Failed to deploy the model: Parameter validation failed:
Invalid type for parameter PrimaryContainer.Environment.container_startup_health_check_timeout, value: 300, type: <class 'int'>, valid types: <class 'str'>
2024-11-02 11:47:08,446 - inference - INFO - Attempting to deploy the base model instead...
2024-11-02 11:53:12,393 - inference - INFO - Base model deployed successfully: HuggingFacePredictor: {'endpoint_name': 'huggingface-pytorch-tgi-inference-2024-11-02-14-47-09-611', 'sagemaker_session': <sagemaker.session.Session object at 0x0000023CEA8E2C20>, 'serializer': <sagemaker.base_serializers.JSONSerializer object at 0x0000023CE95FB820>, 'deserializer': <sagemaker.base_deserializers.JSONDeserializer object at 0x0000023CE95FB3D0>}
2024-11-02 11:53:12,760 - inference - INFO - Endpoint information saved to MLflow with run ID: 39329c5240504b789faab9c031d07478
2024-11-02 12:53:53,725 - inference - INFO - Loading AWS connections...
2024-11-02 12:53:57,325 - inference - INFO - Loading model uri for sagemaker deployment...
2024-11-02 12:53:58,821 - inference - INFO - Retrieving LLM image URI and deployment configuration...
2024-11-02 12:53:59,396 - inference - INFO - Deploying the model as a SageMaker endpoint...
2024-11-02 12:54:00,000 - inference - ERROR - Failed to deploy the model: Parameter validation failed:
Invalid type for parameter PrimaryContainer.Environment.container_startup_health_check_timeout, value: 300, type: <class 'int'>, valid types: <class 'str'>
2024-11-02 12:54:00,001 - inference - INFO - Attempting to deploy the base model instead...
2024-11-02 13:00:03,821 - inference - INFO - Base model deployed successfully: HuggingFacePredictor: {'endpoint_name': 'huggingface-pytorch-tgi-inference-2024-11-02-15-54-01-206', 'sagemaker_session': <sagemaker.session.Session object at 0x000001E5E3036BF0>, 'serializer': <sagemaker.base_serializers.JSONSerializer object at 0x000001E5E1D4F820>, 'deserializer': <sagemaker.base_deserializers.JSONDeserializer object at 0x000001E5E1D4F3D0>}
2024-11-02 13:00:04,719 - inference - INFO - Endpoint information saved to MLflow with run ID: e0ee045b48d84189bf7011562b42153c
2024-11-02 15:06:57,982 - inference - INFO - Loading AWS connections...
2024-11-02 15:07:01,664 - inference - INFO - Loading model uri for sagemaker deployment...
2024-11-02 15:07:03,278 - inference - INFO - Retrieving LLM image URI and deployment configuration...
2024-11-02 15:07:03,685 - inference - INFO - Deploying the model as a SageMaker endpoint...
2024-11-02 15:07:04,376 - inference - ERROR - Failed to deploy the model: Parameter validation failed:
Invalid type for parameter PrimaryContainer.Environment.container_startup_health_check_timeout, value: 300, type: <class 'int'>, valid types: <class 'str'>
2024-11-02 15:07:04,380 - inference - INFO - Attempting to deploy the base model instead...
2024-11-02 15:13:08,289 - inference - INFO - Base model deployed successfully: HuggingFacePredictor: {'endpoint_name': 'huggingface-pytorch-tgi-inference-2024-11-02-18-07-05-569', 'sagemaker_session': <sagemaker.session.Session object at 0x00000235EEC4BDC0>, 'serializer': <sagemaker.base_serializers.JSONSerializer object at 0x00000235ED21F430>, 'deserializer': <sagemaker.base_deserializers.JSONDeserializer object at 0x00000235ED21E590>}
2024-11-02 15:13:08,812 - inference - INFO - Endpoint information saved to MLflow with run ID: 0e94a7794b614d978e33993d28f7617f
2024-11-02 15:25:24,067 - inference - INFO - Loading AWS connections...
2024-11-02 15:25:27,596 - inference - INFO - Loading model uri for sagemaker deployment...
2024-11-02 15:25:28,872 - inference - INFO - Retrieving LLM image URI and deployment configuration...
2024-11-02 15:25:29,315 - inference - INFO - Deploying the model as a SageMaker endpoint...
2024-11-02 15:25:29,950 - inference - ERROR - Failed to deploy the model: Parameter validation failed:
Invalid type for parameter PrimaryContainer.Environment.container_startup_health_check_timeout, value: 300, type: <class 'int'>, valid types: <class 'str'>
2024-11-02 15:25:29,951 - inference - INFO - Attempting to deploy the base model instead...
2024-11-02 15:32:03,928 - inference - INFO - Base model deployed successfully: huggingface-pytorch-tgi-inference-2024-11-02-18-25-31-152
2024-11-02 15:32:04,453 - inference - INFO - Endpoint information saved to MLflow with run ID: 382f29eba63a4254ae46c03d1aa806c6
